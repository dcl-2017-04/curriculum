title: Parsing basics
theme: wrangle
needs:
- data-structure-basics
- manip-basics
readings: ~
desc: "\nSo far you've worked with data sets that have been bundled in R packages,
  or have been created with `tibble()` or `tribble()`. Now it's time to learn how
  to read simple flat files from disk. To do this, we'll use functions from [readr](http://readr.tidyverse.org).
  readr is one of the core tidyverse packages, so you won't usually load it explicitly.\n\n```
  r\nlibrary(tidyverse)\n#> Loading tidyverse: ggplot2\n#> Loading tidyverse: tibble\n#>
  Loading tidyverse: tidyr\n#> Loading tidyverse: readr\n#> Loading tidyverse: purrr\n#>
  Loading tidyverse: dplyr\n#> Conflicts with tidy packages ----------------------------------------------\n#>
  filter(): dplyr, stats\n#> lag():    dplyr, stats\n```\n\nDelimited files\n---------------\n\nIn
  this unit, we're going to focus on delimited files. Delimited files have a **delimiter**
  between each value. Two types make up the majority of delimited files that you'll
  see in the wild: csv (comma separated) and tsv (tab separated). We'll focus on csv
  files, but everything you'll learn applies equally to tsvs, replacing commas with
  tabs.\n\nA typical csv file looks something like this:\n\n    Sepal.Length,Sepal.Width,Petal.Length,Petal.Width,Species\n
  \   5.1,3.5,1.4,0.2,setosa\n    4.9,3,1.4,0.2,setosa\n    4.7,3.2,1.3,0.2,setosa\n
  \   4.6,3.1,1.5,0.2,setosa\n    5,3.6,1.4,0.2,setosa\n    5.4,3.9,1.7,0.4,setosa\n
  \   4.6,3.4,1.4,0.3,setosa\n    5,3.4,1.5,0.2,setosa\n\nNote that:\n\n-   The first
  line gives the column names\n-   Each subsequent line is one row of data\n-   Each
  value is separated by a comma (hence the name)\n\nTypically you can recognise a
  csv file by its extension: `.csv`. But beware! Sometimes the extension lies, and
  if you're getting weird errors when reading a file, it's a good idea to peek inside
  the file using `readr::read_lines()` and `writeLines()`, specifying the `n_max`
  argument to just look at the first few lines. (You'll learn more about `writeLines()`
  when we get to strings; for now just remember it's a useful tool for printing lines
  to the screen.)\n\n``` r\n\"heights.csv\" %>% \n  read_lines(n_max = 10) %>%\n  writeLines()\n#>
  \"earn\",\"height\",\"sex\",\"ed\",\"age\",\"race\"\n#> 50000,74.4244387818035,\"male\",16,45,\"white\"\n#>
  60000,65.5375428255647,\"female\",16,58,\"white\"\n#> 30000,63.6291977374349,\"female\",16,29,\"white\"\n#>
  50000,63.1085616752971,\"female\",16,91,\"other\"\n#> 51000,63.4024835710879,\"female\",17,39,\"white\"\n#>
  9000,64.3995075440034,\"female\",15,26,\"white\"\n#> 29000,61.6563258264214,\"female\",12,49,\"white\"\n#>
  32000,72.6985437364783,\"male\",17,46,\"white\"\n#> 2000,72.0394668497611,\"male\",15,21,\"hispanic\"\n```\n\nThis
  file illustrates another feature present in many csv files: some values are surrounded
  by quotes. Confusingly, this isn't a guarantee that the value is a string: some
  csv files also surround numbers in quotes too. As you work with more csv files you'll
  discover there are few hard and fast rules: for pretty much every crazy thing that
  you can imagine, someone has done it in a csv file somewhere.\n\n`read_csv()`\n------------\n\nThe
  workhorse for reading in csv files is called `read_csv()`. You give it a path to
  a csv file and it gives you back a tibble:\n\n``` r\nheights <- read_csv(\"heights.csv\")\n#>
  Parsed with column specification:\n#> cols(\n#>   earn = col_double(),\n#>   height
  = col_double(),\n#>   sex = col_character(),\n#>   ed = col_integer(),\n#>   age
  = col_integer(),\n#>   race = col_character()\n#> )\nheights\n#> # A tibble: 1,192
  Ã— 6\n#>     earn   height    sex    ed   age     race\n#>    <dbl>    <dbl>  <chr>
  <int> <int>    <chr>\n#> 1  50000 74.42444   male    16    45    white\n#> 2  60000
  65.53754 female    16    58    white\n#> 3  30000 63.62920 female    16    29    white\n#>
  4  50000 63.10856 female    16    91    other\n#> 5  51000 63.40248 female    17
  \   39    white\n#> 6   9000 64.39951 female    15    26    white\n#> 7  29000 61.65633
  female    12    49    white\n#> 8  32000 72.69854   male    17    46    white\n#>
  9   2000 72.03947   male    15    21 hispanic\n#> 10 27000 72.23493   male    12
  \   26    white\n#> # ... with 1,182 more rows\n```\n\nIf you are very lucky, you
  can point `read_csv()` at a file and it just works. But this is usually the exception,
  not the rule, and often you'll need to tweak some arguments.\n\nThe most important
  arguments to `read_csv()` are:\n\n-   `col_names`: usually `col_names = TRUE` which
  tells `read_csv()` that the first line of the file is the column names. If there
  aren't any column names set `col_names = FALSE` or supply a character vector telling
  `read_csv()` what they should be `col_names = c(\"x\", \"y\", \"z\")`\n\n-   `col_types`:
  you might have noticed that when we called `read_csv()` above it printed out a list
  of column \"specifications\". That describes how readr converts each column into
  an data structure. readr uses some pretty good heuristics to guess the type, but
  sometimes the heuristics fail and you'll need to supply the truth. You'll learn
  more about that later in the course\n\n-   It's fairly common to encounter csv files
  that have a bunch of \U0001F4A9 at the top. You can use `skip = n` to skip the first
  n lines, or `comment = \"#\"` to ignore all lines that start with `#`.\n\n-   `read_csv()`
  excepts missing values to be suppled as `NA`. If your file uses a different convention,
  use `na = \".\"` to override the default.\n\nYou'll get to practice using these
  arguments in the exercises.\n"
